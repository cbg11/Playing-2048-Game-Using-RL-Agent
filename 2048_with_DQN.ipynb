{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbg11/Playing-2048-Game-Using-RL-Agent/blob/main/2048_with_DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "xzaUg3iS-QiZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to save file\n",
        "import pathlib\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "%cd /content/drive/My Drive/RL_project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8zVrLdJ-etE",
        "outputId": "8fb0d9f6-2648-499f-964b-0beeac2ca7e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive/RL_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Game:\n",
        "    def __init__(self):\n",
        "        self.board = np.zeros((4, 4), dtype=np.int32)\n",
        "        self.score = 0\n",
        "        self.game_over = False\n",
        "        self.add_tile()\n",
        "        self.add_tile()\n",
        "\n",
        "    def add_tile(self):\n",
        "        empty_cells = np.where(self.board == 0)\n",
        "        if len(empty_cells[0]) == 0:\n",
        "            return\n",
        "        idx = random.choice(range(len(empty_cells[0])))\n",
        "        value = 2 if random.random() < 0.9 else 4\n",
        "        self.board[empty_cells[0][idx], empty_cells[1][idx]] = value\n",
        "\n",
        "    def move(self, direction):\n",
        "        if direction == 'left':\n",
        "            self.board, moved, reward = move_left(self.board)\n",
        "        elif direction == 'right':\n",
        "            self.board, moved, reward = move_right(self.board)\n",
        "        elif direction == 'up':\n",
        "            self.board, moved, reward = move_up(self.board)\n",
        "        elif direction == 'down':\n",
        "            self.board, moved, reward = move_down(self.board)\n",
        "\n",
        "        if moved:\n",
        "            self.add_tile()\n",
        "            self.score += reward\n",
        "        if (np.count_nonzero(self.board) == 16) and (np.all(self.board[:, :-1] != self.board[:, 1:]) and np.all(self.board[:-1, :] != self.board[1:, :])):\n",
        "            self.game_over = True\n",
        "        return moved, reward\n"
      ],
      "metadata": {
        "id": "vr1vRzx2-kWS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self, n_observations = 16, action_size = 4, gamma=0.99, epsilon=1.0, epsilon_decay=0.999, epsilon_min=0.01, learning_rate=0.001, memory_size=100_000):\n",
        "        self.n_observations = n_observations\n",
        "        self.action_size = action_size\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.learning_rate = learning_rate\n",
        "        self.memory = []\n",
        "        self.memory_size = memory_size\n",
        "        self.model = DQN(self.n_observations,self.action_size)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.loss_fn = nn.MSELoss()\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "        if len(self.memory) > self.memory_size:\n",
        "            del self.memory[0]\n",
        "\n",
        "    def act(self, state, epsilon = None):\n",
        "        if epsilon == None:\n",
        "          epsilon = self.epsilon\n",
        "        else:\n",
        "          epsilon = epsilon\n",
        "        if np.random.rand() < epsilon:\n",
        "            # Explore\n",
        "            return random.randrange(self.action_size)\n",
        "        else:\n",
        "            # Exploit best known action\n",
        "            state = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
        "            q_values = self.model(state)\n",
        "            return torch.argmax(q_values, dim=1).item()\n",
        "\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        if len(self.memory) < batch_size:\n",
        "            return\n",
        "        batch = random.sample(self.memory, batch_size)\n",
        "        states, actions, rewards, next_states, dones = zip(*batch)\n",
        "        states = torch.tensor(states, dtype=torch.float32)\n",
        "        actions = torch.tensor(actions, dtype=torch.int64).unsqueeze(1)\n",
        "        rewards = torch.tensor(rewards, dtype=torch.float32).unsqueeze(1)\n",
        "        next_states = torch.tensor(next_states, dtype=torch.float32)\n",
        "        dones = torch.tensor(dones, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "        q_values = self.model(states).gather(1, actions)\n",
        "        next_q_values = self.model(next_states)\n",
        "        max_next_q_values = torch.max(next_q_values, dim=1, keepdim=True)[0]\n",
        "        expected_q_values = rewards + self.gamma * max_next_q_values * (1 - dones)\n",
        "        loss = self.loss_fn(q_values, expected_q_values)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "          self.epsilon *= self.epsilon_decay"
      ],
      "metadata": {
        "id": "URvUu42X-q25"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "  def __init__(self, n_observations, action_size):\n",
        "    super(DQN, self).__init__()\n",
        "    self.fc1 = nn.Linear(n_observations, 128)\n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    self.fc3 = nn.Linear(64, action_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = torch.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "def preprocess(board):\n",
        "  # Convert the board to a 1D array and take the logarithm of each tile value\n",
        "  board = np.log2(board.flatten() + 1)\n",
        "  # Normalize the board to have zero mean and unit variance\n",
        "  board = (board - board.mean()) / board.std()\n",
        "  return board\n",
        "  \n",
        "def move_left(board):\n",
        "  moved = False\n",
        "  score = 0\n",
        "  for row in range(4):\n",
        "    merged = np.zeros((4,), dtype=bool)\n",
        "    for col in range(1, 4):\n",
        "      if board[row, col] == 0:\n",
        "        continue\n",
        "      for i in range(col):\n",
        "        if board[row, i] == 0:\n",
        "          board[row, i] = board[row, col]\n",
        "          board[row, col] = 0\n",
        "          moved = True\n",
        "          break\n",
        "        elif board[row, i] == board[row, col] and not merged[i]:\n",
        "          board[row, i] *= 2\n",
        "          board[row, col] = 0\n",
        "          merged[i] = True\n",
        "          moved = True\n",
        "          score += board[row, i]\n",
        "          break\n",
        "  return board, moved, score\n",
        "\n",
        "def move_right(board):\n",
        "  board, moved, score = move_left(np.fliplr(board))\n",
        "  return np.fliplr(board), moved, score\n",
        "    \n",
        "def move_up(board):\n",
        "  board, moved, score = move_left(board.T)\n",
        "  return board.T, moved, score\n",
        "\n",
        "def move_down(board):\n",
        "  board, moved, score = move_right(board.T)\n",
        "  return board.T, moved, score\n",
        "\n",
        "def train(agent, episodes, batch_size):\n",
        "  scores = []\n",
        "  for episode in range(episodes):\n",
        "      game = Game()\n",
        "      state = preprocess(game.board)\n",
        "      done = False\n",
        "      while not done:\n",
        "        action = agent.act(state)\n",
        "        moved, reward = game.move(['left', 'up', 'right', 'down'][action])\n",
        "        while not moved:\n",
        "          rand_num = action\n",
        "          while rand_num == action:\n",
        "            rand_num = random.randrange(4)\n",
        "          action = rand_num\n",
        "          moved, reward = game.move(['left', 'up', 'right', 'down'][action])\n",
        "        next_state = preprocess(game.board)\n",
        "        done = game.game_over\n",
        "        agent.remember(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        agent.replay(batch_size)\n",
        "      #print(game.board)\n",
        "      scores.append(game.score)\n",
        "      max_val = max(max(row) for row in game.board)\n",
        "      print(\"Episode: %d, Score: %d, Max Value: %d Epsilon: %.4f\" % (episode, game.score, max_val, agent.epsilon))\n",
        "      if episode % 500 == 0:\n",
        "        torch.save(agent.model.state_dict(), 'model.pth')\n",
        "  return scores"
      ],
      "metadata": {
        "id": "T3XC986B-ty5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  n_observations = 16\n",
        "  action_size = 4\n",
        "  agent = DQNAgent(n_observations, action_size, gamma=0.999)\n",
        "  scores = train(agent, episodes=5001, batch_size=32)\n",
        "  print(\"done\")"
      ],
      "metadata": {
        "id": "dht7KkW2-vy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to display the game board and score\n",
        "def display_board(score, action, grid):\n",
        "    print(f\"\\033[1m\" + \"Score: \", score, \"\\t Action: \"+ action+ \"\\033[0m\")\n",
        "    print(\"+-------+-------+-------+-------+\\n\"\n",
        "          \"|\\t|\\t|\\t|\\t|\\n\"\n",
        "          \"|  {}\\t|  {}\\t|  {}\\t|  {}\\t|\\n\"\n",
        "          \"|\\t|\\t|\\t|\\t|\\n\"\n",
        "          \"+-------+-------+-------+-------+\\n\"\n",
        "          \"|\\t|\\t|\\t|\\t|\\n\"\n",
        "          \"|  {}\\t|  {}\\t|  {}\\t|  {}\\t|\\n\"\n",
        "          \"|\\t|\\t|\\t|\\t|\\n\"\n",
        "          \"+-------+-------+-------+-------+\\n\"\n",
        "          \"|\\t|\\t|\\t|\\t|\\n\"\n",
        "          \"|  {}\\t|  {}\\t|  {}\\t|  {}\\t|\\n\"\n",
        "          \"|\\t|\\t|\\t|\\t|\\n\"\n",
        "          \"+-------+-------+-------+-------+\\n\"\n",
        "          \"|\\t|\\t|\\t|\\t|\\n\"\n",
        "          \"|  {}\\t|  {}\\t|  {}\\t|  {}\\t|\\n\"\n",
        "          \"|\\t|\\t|\\t|\\t|\\n\"\n",
        "          \"+-------+-------+-------+-------+\\n\".format(*[x if x != 0 else \"\" for row in grid for x in row]))\n",
        "def test(agent):\n",
        "    game = Game()\n",
        "    state = preprocess(game.board)\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = agent.act(state, epsilon=0)  # set epsilon=0 to disable exploration\n",
        "        act =['left', 'up', 'right', 'down'][action]\n",
        "        moved, reward = game.move(act)\n",
        "        if not moved:\n",
        "          rand_num = action\n",
        "          while rand_num == action:\n",
        "            rand_num = random.randrange(4)\n",
        "          act =['left', 'up', 'right', 'down'][rand_num]\n",
        "          moved, reward = game.move(act)\n",
        "        state = preprocess(game.board)\n",
        "        done = game.game_over\n",
        "    return game.score, game.board"
      ],
      "metadata": {
        "id": "stAEjn0E-x7F"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    n_observations = 16\n",
        "    action_size = 4\n",
        "    agent = DQNAgent(n_observations, action_size)\n",
        "    agent.model.load_state_dict(torch.load('modelv3.pth'))  # load the saved model\n",
        "    avg_score = 0\n",
        "    max_values = []\n",
        "    num_trials = 100\n",
        "    for i in range(num_trials):\n",
        "        score, board = test(agent)\n",
        "        print(f'Trial {i+1}: score = {score}')\n",
        "        max_val = max(max(row) for row in board)\n",
        "        max_values.append(max_val)\n",
        "        print(f\"Maximum Value: {max_val}\")\n",
        "        avg_score += score\n",
        "    avg_score /= num_trials\n",
        "    print(f'Average score over {num_trials} trials: {avg_score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e5mWDunPjo_",
        "outputId": "3633015b-798f-491e-90b9-37aa37b97e58"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1: score = 7104\n",
            "Maximum Value: 512\n",
            "Trial 2: score = 12328\n",
            "Maximum Value: 1024\n",
            "Trial 3: score = 27060\n",
            "Maximum Value: 2048\n",
            "Trial 4: score = 7072\n",
            "Maximum Value: 512\n",
            "Trial 5: score = 17036\n",
            "Maximum Value: 1024\n",
            "Trial 6: score = 7552\n",
            "Maximum Value: 512\n",
            "Trial 7: score = 12220\n",
            "Maximum Value: 1024\n",
            "Trial 8: score = 12272\n",
            "Maximum Value: 1024\n",
            "Trial 9: score = 5412\n",
            "Maximum Value: 512\n",
            "Trial 10: score = 15748\n",
            "Maximum Value: 1024\n",
            "Trial 11: score = 12204\n",
            "Maximum Value: 1024\n",
            "Trial 12: score = 12072\n",
            "Maximum Value: 1024\n",
            "Trial 13: score = 14368\n",
            "Maximum Value: 1024\n",
            "Trial 14: score = 6964\n",
            "Maximum Value: 512\n",
            "Trial 15: score = 3340\n",
            "Maximum Value: 256\n",
            "Trial 16: score = 16312\n",
            "Maximum Value: 1024\n",
            "Trial 17: score = 3084\n",
            "Maximum Value: 256\n",
            "Trial 18: score = 11892\n",
            "Maximum Value: 1024\n",
            "Trial 19: score = 6352\n",
            "Maximum Value: 512\n",
            "Trial 20: score = 16328\n",
            "Maximum Value: 1024\n",
            "Trial 21: score = 23156\n",
            "Maximum Value: 2048\n",
            "Trial 22: score = 3296\n",
            "Maximum Value: 256\n",
            "Trial 23: score = 16088\n",
            "Maximum Value: 1024\n",
            "Trial 24: score = 21480\n",
            "Maximum Value: 2048\n",
            "Trial 25: score = 16616\n",
            "Maximum Value: 1024\n",
            "Trial 26: score = 3060\n",
            "Maximum Value: 256\n",
            "Trial 27: score = 16360\n",
            "Maximum Value: 1024\n",
            "Trial 28: score = 2764\n",
            "Maximum Value: 256\n",
            "Trial 29: score = 6868\n",
            "Maximum Value: 512\n",
            "Trial 30: score = 1352\n",
            "Maximum Value: 128\n",
            "Trial 31: score = 14124\n",
            "Maximum Value: 1024\n",
            "Trial 32: score = 7536\n",
            "Maximum Value: 512\n",
            "Trial 33: score = 16240\n",
            "Maximum Value: 1024\n",
            "Trial 34: score = 10688\n",
            "Maximum Value: 1024\n",
            "Trial 35: score = 14696\n",
            "Maximum Value: 1024\n",
            "Trial 36: score = 7240\n",
            "Maximum Value: 512\n",
            "Trial 37: score = 16452\n",
            "Maximum Value: 1024\n",
            "Trial 38: score = 13980\n",
            "Maximum Value: 1024\n",
            "Trial 39: score = 16176\n",
            "Maximum Value: 1024\n",
            "Trial 40: score = 11544\n",
            "Maximum Value: 1024\n",
            "Trial 41: score = 15164\n",
            "Maximum Value: 1024\n",
            "Trial 42: score = 5300\n",
            "Maximum Value: 512\n",
            "Trial 43: score = 10660\n",
            "Maximum Value: 1024\n",
            "Trial 44: score = 12860\n",
            "Maximum Value: 1024\n",
            "Trial 45: score = 26416\n",
            "Maximum Value: 2048\n",
            "Trial 46: score = 7152\n",
            "Maximum Value: 512\n",
            "Trial 47: score = 15208\n",
            "Maximum Value: 1024\n",
            "Trial 48: score = 12184\n",
            "Maximum Value: 1024\n",
            "Trial 49: score = 7180\n",
            "Maximum Value: 512\n",
            "Trial 50: score = 7076\n",
            "Maximum Value: 512\n",
            "Trial 51: score = 7540\n",
            "Maximum Value: 512\n",
            "Trial 52: score = 2876\n",
            "Maximum Value: 256\n",
            "Trial 53: score = 23656\n",
            "Maximum Value: 2048\n",
            "Trial 54: score = 16068\n",
            "Maximum Value: 1024\n",
            "Trial 55: score = 7156\n",
            "Maximum Value: 512\n",
            "Trial 56: score = 13612\n",
            "Maximum Value: 1024\n",
            "Trial 57: score = 12152\n",
            "Maximum Value: 1024\n",
            "Trial 58: score = 16240\n",
            "Maximum Value: 1024\n",
            "Trial 59: score = 7064\n",
            "Maximum Value: 512\n",
            "Trial 60: score = 7448\n",
            "Maximum Value: 512\n",
            "Trial 61: score = 7384\n",
            "Maximum Value: 512\n",
            "Trial 62: score = 15732\n",
            "Maximum Value: 1024\n",
            "Trial 63: score = 10804\n",
            "Maximum Value: 1024\n",
            "Trial 64: score = 7120\n",
            "Maximum Value: 512\n",
            "Trial 65: score = 6632\n",
            "Maximum Value: 512\n",
            "Trial 66: score = 14736\n",
            "Maximum Value: 1024\n",
            "Trial 67: score = 16200\n",
            "Maximum Value: 1024\n",
            "Trial 68: score = 16084\n",
            "Maximum Value: 1024\n",
            "Trial 69: score = 16284\n",
            "Maximum Value: 1024\n",
            "Trial 70: score = 16104\n",
            "Maximum Value: 1024\n",
            "Trial 71: score = 32960\n",
            "Maximum Value: 2048\n",
            "Trial 72: score = 7260\n",
            "Maximum Value: 512\n",
            "Trial 73: score = 4924\n",
            "Maximum Value: 512\n",
            "Trial 74: score = 14412\n",
            "Maximum Value: 1024\n",
            "Trial 75: score = 27284\n",
            "Maximum Value: 2048\n",
            "Trial 76: score = 23260\n",
            "Maximum Value: 2048\n",
            "Trial 77: score = 27620\n",
            "Maximum Value: 2048\n",
            "Trial 78: score = 26996\n",
            "Maximum Value: 2048\n",
            "Trial 79: score = 22792\n",
            "Maximum Value: 2048\n",
            "Trial 80: score = 31640\n",
            "Maximum Value: 2048\n",
            "Trial 81: score = 15760\n",
            "Maximum Value: 1024\n",
            "Trial 82: score = 15516\n",
            "Maximum Value: 1024\n",
            "Trial 83: score = 16232\n",
            "Maximum Value: 1024\n",
            "Trial 84: score = 15896\n",
            "Maximum Value: 1024\n",
            "Trial 85: score = 15784\n",
            "Maximum Value: 1024\n",
            "Trial 86: score = 3168\n",
            "Maximum Value: 256\n",
            "Trial 87: score = 23240\n",
            "Maximum Value: 2048\n",
            "Trial 88: score = 15356\n",
            "Maximum Value: 1024\n",
            "Trial 89: score = 16192\n",
            "Maximum Value: 1024\n",
            "Trial 90: score = 6584\n",
            "Maximum Value: 512\n",
            "Trial 91: score = 15288\n",
            "Maximum Value: 1024\n",
            "Trial 92: score = 5448\n",
            "Maximum Value: 512\n",
            "Trial 93: score = 14424\n",
            "Maximum Value: 1024\n",
            "Trial 94: score = 14776\n",
            "Maximum Value: 1024\n",
            "Trial 95: score = 6188\n",
            "Maximum Value: 512\n",
            "Trial 96: score = 23916\n",
            "Maximum Value: 2048\n",
            "Trial 97: score = 15476\n",
            "Maximum Value: 1024\n",
            "Trial 98: score = 7100\n",
            "Maximum Value: 512\n",
            "Trial 99: score = 14784\n",
            "Maximum Value: 1024\n",
            "Trial 100: score = 12152\n",
            "Maximum Value: 1024\n",
            "Average score over 100 trials: 13189.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_list(list_to_plot):\n",
        "    x = range(len(list_to_plot))\n",
        "    y = list_to_plot\n",
        "    plt.scatter(x, y)\n",
        "    plt.show()\n",
        "plot_list(max_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "iqdKElh2uY8s",
        "outputId": "20b5fea3-e9b6-4ecb-a986-ac58252ad89b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i in max_values:\n",
        "  if i == 2048:\n",
        "    count += 1\n",
        "count "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcTXt4kArijE",
        "outputId": "5fa5676a-8754-48e6-ea84-852cd92643f6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def play_game(agent):\n",
        "    game = Game()\n",
        "    state = preprocess(game.board)\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = agent.act(state, epsilon=0)  # set epsilon=0 to disable exploration\n",
        "        act =['left', 'up', 'right', 'down'][action]\n",
        "        moved, reward = game.move(act)\n",
        "        if not moved:\n",
        "          rand_num = action\n",
        "          while rand_num == action:\n",
        "            rand_num = random.randrange(4)\n",
        "          act =['left', 'up', 'right', 'down'][rand_num]\n",
        "          moved, reward = game.move(act)\n",
        "        clear_output(wait=True)\n",
        "        display_board(game.score, act, game.board)\n",
        "        time.sleep(2)\n",
        "\n",
        "        done = game.game_over\n",
        "    return game.score, game.board"
      ],
      "metadata": {
        "id": "oHvnMTb5o4C9"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Play the game\n",
        "def play():\n",
        "  agent = DQNAgent(16, 4)\n",
        "  agent.model.load_state_dict(torch.load('modelv3.pth'))  # load the saved model\n",
        "  score, board = play_game(agent)\n",
        "  print(\"Game Over!\")\n",
        "  print(\"Final Score:\", score)\n",
        "play()"
      ],
      "metadata": {
        "id": "qVRpUaEf0Vlg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3656518a-b639-45c3-8e53-cde15db917bd"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mScore:  23148 \t Action: left\u001b[0m\n",
            "+-------+-------+-------+-------+\n",
            "|\t|\t|\t|\t|\n",
            "|  8\t|  16\t|  4\t|  2\t|\n",
            "|\t|\t|\t|\t|\n",
            "+-------+-------+-------+-------+\n",
            "|\t|\t|\t|\t|\n",
            "|  2048\t|  8\t|  16\t|  4\t|\n",
            "|\t|\t|\t|\t|\n",
            "+-------+-------+-------+-------+\n",
            "|\t|\t|\t|\t|\n",
            "|  128\t|  256\t|  4\t|  2\t|\n",
            "|\t|\t|\t|\t|\n",
            "+-------+-------+-------+-------+\n",
            "|\t|\t|\t|\t|\n",
            "|  2\t|  32\t|  64\t|  4\t|\n",
            "|\t|\t|\t|\t|\n",
            "+-------+-------+-------+-------+\n",
            "\n",
            "Game Over!\n",
            "Final Score: 23148\n"
          ]
        }
      ]
    }
  ]
}